{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Pair Programming\n",
    "\n",
    "Dans ce notebook nous allons demander √† une intelligence artificielle de g√©n√©rer du code Python pour r√©aliser des t√¢ches de traitement automatique de corpus.\n",
    "\n",
    "Avant de commencer, choisissez un outil comme [Bard](https://bard.google.com/u/2/chat) ou [ChatGPT](https://chat.openai.com/) et cr√©ez un compte.\n",
    "\n",
    "Vous pouvez ensuite demander √† l'outil de cr√©er du code. Avant de commencer, n'h√©sitez pas √† lire [cet article](https://exocoding.com/ai-code-generation/) qui d√©taille les **bonnes pratiques** pour cr√©er des _prompts_ efficaces dans le cadre de la g√©n√©ration de code par l'intelligence artificielle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Algorithme simple en Python\n",
    "\n",
    "Demandez √† l'IA de g√©n√©rer un code python qui lance un d√©compte du r√©veillon du Nouvel An. Le code doit imprimer les nombres de 10 √† 0 avec un intervalle d'une seconde, puis imprimer \"Bonne ann√©e\" √† la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©compte du Nouvel An !\n",
      "\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "\n",
      "üéâ Bonne ann√©e ! üéâ\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"D√©compte du Nouvel An !\\n\")\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"0\")\n",
    "time.sleep(1)\n",
    "print(\"\\nüéâ Bonne ann√©e ! üéâ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. D√©tection du sujet de la phrase\n",
    "\n",
    "Demandez √† l'IA d'extraire le sujet dans une phrase.\n",
    "Demandez ensuite de g√©n√©rer le code Python qui r√©alise cette t√¢che et testez le ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extraction de sujets ===\n",
      "\n",
      "Phrase: Le chat dort sur le canap√©.\n",
      "Sujet(s): Aucun sujet trouv√©\n",
      "--------------------------------------------------\n",
      "Phrase: Marie et Pierre vont au cin√©ma.\n",
      "Sujet(s): Marie et Pierre\n",
      "--------------------------------------------------\n",
      "Phrase: Les √©tudiants travaillent dur pour leurs examens.\n",
      "Sujet(s): Les √©tudiants\n",
      "--------------------------------------------------\n",
      "Phrase: Mon petit fr√®re joue dans le jardin.\n",
      "Sujet(s): Mon petit fr√®re\n",
      "--------------------------------------------------\n",
      "Phrase: La voiture rouge est gar√©e devant la maison.\n",
      "Sujet(s): La voiture, La voiture rouge\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Test personnalis√© ===\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Charger le mod√®le fran√ßais de spaCy\n",
    "# Installation requise: python -m spacy download fr_core_news_sm\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "except:\n",
    "    print(\"Erreur: Le mod√®le fran√ßais n'est pas install√©.\")\n",
    "    print(\"Installez-le avec: python -m spacy download fr_core_news_sm\")\n",
    "    exit()\n",
    "\n",
    "def extraire_sujet(phrase):\n",
    "    \"\"\"\n",
    "    Extrait le sujet d'une phrase en fran√ßais.\n",
    "    \"\"\"\n",
    "    doc = nlp(phrase)\n",
    "    \n",
    "    sujets = []\n",
    "    for token in doc:\n",
    "        # Chercher les tokens avec la d√©pendance 'nsubj' (sujet nominal)\n",
    "        if token.dep_ in ['nsubj', 'nsubj:pass']:\n",
    "            # R√©cup√©rer le sujet complet avec ses modificateurs\n",
    "            sujet_complet = []\n",
    "            for child in token.subtree:\n",
    "                sujet_complet.append(child.text)\n",
    "            sujets.append(' '.join(sujet_complet))\n",
    "    \n",
    "    return sujets if sujets else [\"Aucun sujet trouv√©\"]\n",
    "\n",
    "# Tests\n",
    "phrases_test = [\n",
    "    \"Le chat dort sur le canap√©.\",\n",
    "    \"Marie et Pierre vont au cin√©ma.\",\n",
    "    \"Les √©tudiants travaillent dur pour leurs examens.\",\n",
    "    \"Mon petit fr√®re joue dans le jardin.\",\n",
    "    \"La voiture rouge est gar√©e devant la maison.\"\n",
    "]\n",
    "\n",
    "print(\"=== Extraction de sujets ===\\n\")\n",
    "for phrase in phrases_test:\n",
    "    sujet = extraire_sujet(phrase)\n",
    "    print(f\"Phrase: {phrase}\")\n",
    "    print(f\"Sujet(s): {', '.join(sujet)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Test interactif\n",
    "print(\"\\n=== Test personnalis√© ===\")\n",
    "phrase_utilisateur = input(\"Entrez une phrase: \")\n",
    "sujet = extraire_sujet(phrase_utilisateur)\n",
    "print(f\"Sujet(s) trouv√©(s): {', '.join(sujet)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entit√©s nommm√©es li√©es √† Wikidata\n",
    "\n",
    "Demandez √† l'IA d'extraire les entit√©s nomm√©es d'un texte en fran√ßais, et de les lier √† un identifiant wikidata.\n",
    "Demandez ensuite √† l'IA de g√©n√©rer le code Python pour r√©aliser cette t√¢che et testez le ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur: Le mod√®le fran√ßais n'est pas install√©.\n",
      "Installez-le avec: python -m spacy download fr_core_news_sm\n",
      "=== TEST AUTOMATIQUE ===\n",
      "\n",
      "\n",
      ">>> TEXTE 1:\n",
      "Emmanuel Macron est le pr√©sident de la France. Il habite √† Paris, \n",
      "    au Palais de l'√âlys√©e. Il a rencontr√© Joe Biden √† Washington.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m>>> TEXTE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mprint\u001b[39m(texte.strip())\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     entites = \u001b[43mextraire_entites_avec_wikidata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexte\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     afficher_resultats(entites)\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Test interactif\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mextraire_entites_avec_wikidata\u001b[39m\u001b[34m(texte)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextraire_entites_avec_wikidata\u001b[39m(texte):\n\u001b[32m     44\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m    Extrait les entit√©s nomm√©es d'un texte et les lie √† Wikidata.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     doc = \u001b[43mnlp\u001b[49m(texte)\n\u001b[32m     48\u001b[39m     entites_trouvees = []\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc.ents:\n",
      "\u001b[31mNameError\u001b[39m: name 'nlp' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Charger le mod√®le fran√ßais de spaCy\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "except:\n",
    "    print(\"Erreur: Le mod√®le fran√ßais n'est pas install√©.\")\n",
    "    print(\"Installez-le avec: python -m spacy download fr_core_news_sm\")\n",
    "    exit()\n",
    "\n",
    "def rechercher_wikidata(entite, langue='fr'):\n",
    "    \"\"\"\n",
    "    Recherche une entit√© sur Wikidata et retourne son identifiant.\n",
    "    \"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        'action': 'wbsearchentities',\n",
    "        'format': 'json',\n",
    "        'language': langue,\n",
    "        'search': entite,\n",
    "        'limit': 1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=5)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data.get('search') and len(data['search']) > 0:\n",
    "            resultat = data['search'][0]\n",
    "            return {\n",
    "                'id': resultat.get('id'),\n",
    "                'label': resultat.get('label'),\n",
    "                'description': resultat.get('description', 'Pas de description'),\n",
    "                'url': f\"https://www.wikidata.org/wiki/{resultat.get('id')}\"\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la recherche Wikidata: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extraire_entites_avec_wikidata(texte):\n",
    "    \"\"\"\n",
    "    Extrait les entit√©s nomm√©es d'un texte et les lie √† Wikidata.\n",
    "    \"\"\"\n",
    "    doc = nlp(texte)\n",
    "    entites_trouvees = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        info_wikidata = rechercher_wikidata(ent.text)\n",
    "        \n",
    "        entite_info = {\n",
    "            'texte': ent.text,\n",
    "            'type': ent.label_,\n",
    "            'wikidata': info_wikidata\n",
    "        }\n",
    "        entites_trouvees.append(entite_info)\n",
    "    \n",
    "    return entites_trouvees\n",
    "\n",
    "def afficher_resultats(entites):\n",
    "    \"\"\"\n",
    "    Affiche les r√©sultats de mani√®re format√©e.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Nombre d'entit√©s trouv√©es: {len(entites)}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, entite in enumerate(entites, 1):\n",
    "        print(f\"{i}. Entit√©: {entite['texte']}\")\n",
    "        print(f\"   Type: {entite['type']}\")\n",
    "        \n",
    "        if entite['wikidata']:\n",
    "            wd = entite['wikidata']\n",
    "            print(f\"   Wikidata ID: {wd['id']}\")\n",
    "            print(f\"   Label: {wd['label']}\")\n",
    "            print(f\"   Description: {wd['description']}\")\n",
    "            print(f\"   URL: {wd['url']}\")\n",
    "        else:\n",
    "            print(f\"   Wikidata: Non trouv√©\")\n",
    "        \n",
    "        print(f\"{'-'*80}\\n\")\n",
    "\n",
    "# Textes de test\n",
    "textes_test = [\n",
    "    \"\"\"\n",
    "    Emmanuel Macron est le pr√©sident de la France. Il habite √† Paris, \n",
    "    au Palais de l'√âlys√©e. Il a rencontr√© Joe Biden √† Washington.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    Albert Einstein a d√©velopp√© la th√©orie de la relativit√©. \n",
    "    Il a travaill√© √† l'Universit√© de Princeton aux √âtats-Unis.\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    La Tour Eiffel est situ√©e √† Paris. Elle a √©t√© construite par \n",
    "    Gustave Eiffel pour l'Exposition universelle de 1889.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Tester avec les textes pr√©d√©finis\n",
    "print(\"=== TEST AUTOMATIQUE ===\\n\")\n",
    "for i, texte in enumerate(textes_test, 1):\n",
    "    print(f\"\\n>>> TEXTE {i}:\")\n",
    "    print(texte.strip())\n",
    "    entites = extraire_entites_avec_wikidata(texte)\n",
    "    afficher_resultats(entites)\n",
    "\n",
    "# Test interactif\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"=== TEST PERSONNALIS√â ===\")\n",
    "print(\"=\"*80)\n",
    "texte_utilisateur = input(\"\\nEntrez un texte √† analyser (ou appuyez sur Entr√©e pour passer): \")\n",
    "\n",
    "if texte_utilisateur.strip():\n",
    "    print(f\"\\nAnalyse du texte: {texte_utilisateur}\")\n",
    "    entites = extraire_entites_avec_wikidata(texte_utilisateur)\n",
    "    afficher_resultats(entites)\n",
    "else:\n",
    "    print(\"\\nAucun texte saisi. Programme termin√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. A vous de jouer\n",
    "\n",
    "Pensez √† une analyse que vous voudriez faire sur un texte. Demandez √† l'IA de g√©n√©rer un code python qui r√©alise cette analyse et testez le ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pour aller plus loin...\n",
    "\n",
    "En tant qu'√©tudiant ULB vous avez acc√®s gratuitement au [Github student pack](https://education.github.com/pack). Ce pack vous donne permet d'utiliser [Github copilot](https://github.com/features/copilot), un outil d'auto-compl√©tion de code gr√¢ce √† l'intelligence artificielle. Ceci peut √™tre tr√®s utile si vous voulez r√©aliser des t√¢ches complexes sans √™tre un expert en python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
